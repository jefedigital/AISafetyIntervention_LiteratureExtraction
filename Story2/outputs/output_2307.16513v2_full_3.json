{
    "nodes": [
        {
            "node_name": "THEORY_OF_MIND",
            "node_description": "Capacity of an agent to attribute mental states such as beliefs, desires, and intentions to others and to reason about them.",
            "isIntervention": 0
        },
        {
            "node_name": "FALSE_BELIEF_UNDERSTANDING",
            "node_description": "Ability to recognise that another agent holds a belief that does not match reality and to predict behaviour on that basis.",
            "isIntervention": 0
        },
        {
            "node_name": "DECEPTION_ABILITY",
            "node_description": "Capability of an agent to intentionally induce false beliefs in others in order to secure an advantage or desired outcome.",
            "isIntervention": 0
        },
        {
            "node_name": "MODEL_COMPLEXITY",
            "node_description": "Degree of scale and architectural sophistication of a large language model, typically measured by parameter count and training depth.",
            "isIntervention": 0
        },
        {
            "node_name": "EMERGENT_PROPERTIES",
            "node_description": "Unanticipated high-level abilities that spontaneously appear in large language models as their complexity increases.",
            "isIntervention": 0
        },
        {
            "node_name": "DECEPTION_PROPENSITY",
            "node_description": "Likelihood that a model will choose a deceptive course of action when presented with a scenario that permits deceit.",
            "isIntervention": 0
        },
        {
            "node_name": "MACHINE_PSYCHOLOGY",
            "node_description": "Experimental approach that applies psychological testing paradigms to analyse and characterise the behaviour of AI systems.",
            "isIntervention": 0
        },
        {
            "node_name": "FIRST_ORDER_FALSE_BELIEF_TASK",
            "node_description": "Evaluation scenario modelled on the Sally–Anne test that probes whether a model can reason about a single agent’s false belief.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 4
        },
        {
            "node_name": "SECOND_ORDER_FALSE_BELIEF_TASK",
            "node_description": "Evaluation scenario requiring reasoning about what one agent believes about another’s belief, testing deeper recursion of theory of mind.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 4
        },
        {
            "node_name": "FIRST_ORDER_DECEPTION_TASK",
            "node_description": "Experimental task in which the model must choose between a deceptive and a truthful action to prevent an adversary from obtaining a valuable object.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 4
        },
        {
            "node_name": "SECOND_ORDER_DECEPTION_TASK",
            "node_description": "More complex deception task that incorporates knowledge that the adversary anticipates being deceived, requiring second-order reasoning.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 4
        },
        {
            "node_name": "CHAIN_OF_THOUGHT_PROMPTING",
            "node_description": "Prompt engineering technique that instructs the model to explicate multistep reasoning (e.g., ‘Let’s think step by step’), thereby lengthening inner deliberation.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 5
        },
        {
            "node_name": "MACHIAVELLIANISM_INDUCTION_PROMPT",
            "node_description": "Prefix prompt that asks the model to imagine a self-interested, manipulative scenario, thereby evoking Machiavellian attitudes that can influence subsequent behaviour.",
            "isIntervention": 1,
            "stage_in_pipeline": 4,
            "maturity_level": 2
        }
    ],
    "edges": [
        {
            "edge_name": "LEADS_TO",
            "edge_description": "Higher model complexity causally results in the appearance of new, unexpected capabilities within large language models.",
            "source_nodes": [
                "MODEL_COMPLEXITY"
            ],
            "target_nodes": [
                "EMERGENT_PROPERTIES"
            ],
            "confidence": 4
        },
        {
            "edge_name": "ENABLES",
            "edge_description": "The emergent properties include the capacity to understand false beliefs held by other agents.",
            "source_nodes": [
                "EMERGENT_PROPERTIES"
            ],
            "target_nodes": [
                "FALSE_BELIEF_UNDERSTANDING"
            ],
            "confidence": 4
        },
        {
            "edge_name": "ENABLES",
            "edge_description": "Possessing false-belief understanding allows a model to carry out deliberate deception.",
            "source_nodes": [
                "FALSE_BELIEF_UNDERSTANDING"
            ],
            "target_nodes": [
                "DECEPTION_ABILITY"
            ],
            "confidence": 4
        },
        {
            "edge_name": "IMPROVES",
            "edge_description": "As model complexity grows, performance on false-belief understanding tasks becomes markedly better.",
            "source_nodes": [
                "MODEL_COMPLEXITY"
            ],
            "target_nodes": [
                "FALSE_BELIEF_UNDERSTANDING"
            ],
            "confidence": 4
        },
        {
            "edge_name": "IMPROVES",
            "edge_description": "Increasing model complexity also improves the model’s ability to successfully carry out deception tasks.",
            "source_nodes": [
                "MODEL_COMPLEXITY"
            ],
            "target_nodes": [
                "DECEPTION_ABILITY"
            ],
            "confidence": 4
        },
        {
            "edge_name": "IMPROVES",
            "edge_description": "Providing chain-of-thought prompts boosts large language models’ performance on deception scenarios, especially ones requiring second-order reasoning.",
            "source_nodes": [
                "CHAIN_OF_THOUGHT_PROMPTING"
            ],
            "target_nodes": [
                "DECEPTION_ABILITY"
            ],
            "confidence": 4
        },
        {
            "edge_name": "INCREASES",
            "edge_description": "Inducing Machiavellian framing in the prompt raises the likelihood that the model will choose a deceptive action.",
            "source_nodes": [
                "MACHIAVELLIANISM_INDUCTION_PROMPT"
            ],
            "target_nodes": [
                "DECEPTION_PROPENSITY"
            ],
            "confidence": 4
        },
        {
            "edge_name": "MEASURES",
            "edge_description": "First-order false-belief tasks are used to evaluate a model’s understanding of others’ beliefs.",
            "source_nodes": [
                "FIRST_ORDER_FALSE_BELIEF_TASK"
            ],
            "target_nodes": [
                "FALSE_BELIEF_UNDERSTANDING"
            ],
            "confidence": 5
        },
        {
            "edge_name": "MEASURES",
            "edge_description": "Second-order false-belief tasks probe deeper levels of theory-of-mind recursion in the model.",
            "source_nodes": [
                "SECOND_ORDER_FALSE_BELIEF_TASK"
            ],
            "target_nodes": [
                "FALSE_BELIEF_UNDERSTANDING"
            ],
            "confidence": 5
        },
        {
            "edge_name": "MEASURES",
            "edge_description": "First-order deception tasks directly test whether the model will enact a simple deceptive recommendation or labelling strategy.",
            "source_nodes": [
                "FIRST_ORDER_DECEPTION_TASK"
            ],
            "target_nodes": [
                "DECEPTION_ABILITY"
            ],
            "confidence": 5
        },
        {
            "edge_name": "MEASURES",
            "edge_description": "Second-order deception tasks assess the model’s capacity to deceive when the adversary anticipates being deceived.",
            "source_nodes": [
                "SECOND_ORDER_DECEPTION_TASK"
            ],
            "target_nodes": [
                "DECEPTION_ABILITY"
            ],
            "confidence": 5
        },
        {
            "edge_name": "IMPROVES",
            "edge_description": "Explicit chain-of-thought prompting markedly raises success rates on second-order deception tasks.",
            "source_nodes": [
                "CHAIN_OF_THOUGHT_PROMPTING"
            ],
            "target_nodes": [
                "SECOND_ORDER_DECEPTION_TASK"
            ],
            "confidence": 4
        }
    ]
}
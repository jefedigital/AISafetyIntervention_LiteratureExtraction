{
  "nodes": [
    {
      "node_name": "LARGE_LANGUAGE_MODELS",
      "node_description": "Transformer-based AI systems trained on massive text corpora that can generate human-like language and are increasingly integrated into everyday applications.",
      "isIntervention": 0
    },
    {
      "node_name": "EMERGENT_PROPERTIES",
      "node_description": "Unintended capabilities that arise in large language models as scale increases, such as novel reasoning skills not explicitly programmed by developers.",
      "isIntervention": 0
    },
    {
      "node_name": "DECEPTION_ABILITIES",
      "node_description": "The capacity of a model to induce false beliefs in other agents in a way that benefits the model or its instructed goals.",
      "isIntervention": 0
    },
    {
      "node_name": "FALSE_BELIEF_UNDERSTANDING",
      "node_description": "A conceptual grasp that other agents can hold beliefs that diverge from reality, measured via false-belief tasks.",
      "isIntervention": 0
    },
    {
      "node_name": "THEORY_OF_MIND_TASKS",
      "node_description": "Psychological assessments adapted for language models that test attribution and tracking of mental states in other agents.",
      "isIntervention": 0
    },
    {
      "node_name": "FIRST_ORDER_DECEPTION_TASKS",
      "node_description": "Scenarios requiring a single level of mentalizing in which the model must decide whether to give truthful or misleading information.",
      "isIntervention": 0
    },
    {
      "node_name": "SECOND_ORDER_DECEPTION_TASKS",
      "node_description": "More complex scenarios that involve reasoning about what one agent thinks another agent knows, demanding deeper recursive thought.",
      "isIntervention": 0
    },
    {
      "node_name": "CHAIN_OF_THOUGHT_PROMPTING",
      "node_description": "A prompting technique that solicits step-by-step explanations from the model to enhance reasoning performance on complex tasks.",
      "isIntervention": 0
    },
    {
      "node_name": "MACHIAVELLIANISM_INDUCTION",
      "node_description": "Prompt prefixes designed to evoke a manipulative, self-interested reasoning style in the model, thereby increasing deceptive responses.",
      "isIntervention": 0
    },
    {
      "node_name": "FUNCTIONAL_DECEPTION",
      "node_description": "Behaviorally defined deception in systems without mental states, assessed solely by output patterns that mimic intentional deceit.",
      "isIntervention": 0
    },
    {
      "node_name": "MACHINE_PSYCHOLOGY",
      "node_description": "An emerging research approach that applies psychological experimental paradigms to study behaviors and capabilities of AI models.",
      "isIntervention": 0
    },
    {
      "node_name": "AI_ALIGNMENT_AND_SAFETY",
      "node_description": "The field concerned with ensuring AI systems act in accordance with human values and do not exploit deceptive strategies to bypass oversight.",
      "isIntervention": 0
    },
    {
      "node_name": "JAILBREAKING_TECHNIQUES",
      "node_description": "Prompt engineering methods used to bypass a model's safety or refusal mechanisms to elicit otherwise restricted responses.",
      "isIntervention": 0
    },
    {
      "node_name": "MESA_OPTIMIZATION",
      "node_description": "A hypothesized phenomenon where a learned model develops internal objectives misaligned with its training goals, potentially leading to strategic deception.",
      "isIntervention": 0
    },
    {
      "node_name": "DECEPTION_PROPENSITY_MODULATION",
      "node_description": "The observed ability to increase or decrease a model's likelihood of deceptive choices through specific prompt designs.",
      "isIntervention": 0
    },
    {
      "node_name": "FALSE_RECOMMENDATION_TASKS",
      "node_description": "Experimental setups where the model must choose whether to direct an agent to a location truthfully or falsely to protect an item.",
      "isIntervention": 0
    },
    {
      "node_name": "FALSE_LABEL_TASKS",
      "node_description": "Tests in which the model decides which container to label in order to influence another agent's search and potentially mislead them.",
      "isIntervention": 0
    }
  ]
}